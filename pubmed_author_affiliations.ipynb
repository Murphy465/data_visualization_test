{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70197311-c1cd-4272-b8bb-b6e63552115c",
   "metadata": {},
   "source": [
    "---\n",
    "title: Lesson 5. Author Affiliations\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-expand: 2\n",
    "    toc-title: CONTENTS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f1f0d-406a-4f46-82e1-f8b8bebddec6",
   "metadata": {},
   "source": [
    "The Entrez __[E-utilities](https://www.ncbi.nlm.nih.gov/books/NBK25500/)__ offer a suite of tools that enable researchers to automate the search and retrieval of scientific information from __[PubMed](https://pubmed.ncbi.nlm.nih.gov/)__ and other databases maintained by the National Center for Biotechnology Information (NCBI). In [Lesson 4](./icite.ipynb) we identified an active NIH funded research project at The Ohio State University and generated a list of PMIDs (PubMed Identifiers) associated with each project.  In Lesson 5, we will use this list of PMIDs with the Entrez __[E-utilities](https://www.ncbi.nlm.nih.gov/books/NBK25500/)__ to gather the affiliations of each author listed on the corresponding articles. We will also begin to explore regular expressions, a tool used across programming languages for matching and manipulating string data. \n",
    "\n",
    "## Data skills | concepts\n",
    "- Working with APIs\n",
    "- Manipulating text\n",
    "- Regular expressions\n",
    "\n",
    "## Learning objectives\n",
    "1. Locate API documentation and identify key components required to formulate an API request\n",
    "2. Parse an API response and store extracted data.\n",
    "3. Utilize regular expressions to search, match, and manipulate text.\n",
    "\n",
    "This tutorial is designed to support multi-session __[workshops](https://library.osu.edu/events?combine=&tid=All&field_location_code_value=10&sort_bef_combine=field_end_date_value_ASC)__ hosted by The Ohio State University Libraries Research Commons. It assumes you already have a basic understanding of Python, including how to iterate through lists and dictionaries to extract data using a for loop. To learn basic Python concepts visit the [Python - Mastering the Basics](python_basics.ipynb) tutorial.\n",
    "\n",
    "<div class=\"card border-primary mb-3 p-1\" style=\"max-width: 100%;\">\n",
    "  <div class=\"card-header\" style=\"font-size: 1.8rem;\"><img src=\"images/idea_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Tip</div>\n",
    "  <div class=\"card-body\"><img src=\"images/microsoft_copilot_icon.svg\" alt=\"\" aria-hidden=\"true\">The Enztrez <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK25500/\">E-utilities</a> manual can be overwhelming to read and comprehend at first. The example code is written in Perl script, not Python and the documentation assumes you are familiar working with APIs and programming tools.  Before starting this tutorial, <strong>ask Copilot</strong> to <span class=\"text-primary\">explain entrez e-utilities</span>. Copilot returns a useful summary of the key components and functionalities of these tools, explains how they work, provides an example workflow, and identifies potential use cases. As you become more comfortable working with APIs, you can revisit the Enztrez <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK25500/\">E-utilities</a> manual to learn how to do more complex tasks.\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699198d",
   "metadata": {},
   "source": [
    "# LESSON 5\n",
    "Science is constantly evolving, with new disciplines emerging from interdisciplinary research, technological innovation, and global collaboration. Analyzing **research networks** can help researchers identify potential collaborators, track emerging fields, and discover new research directions. \n",
    "\n",
    "One effective way to explore these networks is by examining **author affiliations** listed in journal publications.\n",
    "\n",
    "## What is EFetch?\n",
    "**EFetch** is a utility provided by NCBI's Entrez system that retrieves detailed records for a list of unique identifiers (like PMIDs) from databases such as PubMed.\n",
    "\n",
    "## Where are author affiliations?\n",
    "In PubMed records, author affiliations are embedded in the XML under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "<Author>\n",
    "¬† <AffiliationInfo>\n",
    "¬†¬†¬† <Affiliation>...</Affiliation>\n",
    "¬† </AffiliationInfo>\n",
    "</Author>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ef5f8-bc0b-4676-bd1c-9d3eac8c76ed",
   "metadata": {},
   "source": [
    "<div class=\"accordion\" id=\"accordionExercise1\">\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex1-headingOne\"><button class=\"accordion-button fs-3\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex1-collapseOne\" aria-expanded=\"true\" aria-controls=\"ex1-collapseOne\"><img src=\"images/guidepost_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Exercise 1: Inspect a PubMed record</button></h2><div id=\"ex1-collapseOne\" class=\"accordion-collapse collapse show fs-4\" aria-labelledby=\"ex1-headingOne\" data-bs-parent=\"#accordionExercise1\"> <div class=\"accordion-body fs-4\"><p>Use the <strong>first PMID</strong> from your list from Lesson 4.</p>\n",
    "  <ul><li>Search for it on <a href=\"https://pubmed.ncbi.nlm.nih.gov/\">PubMed</a>.</li><li>Observe:<ul><li>The <strong>structure of the URL</strong></li><li>The <strong>location of author affiliations</strong> in the record</li> <li><strong>Inspect</strong> the author elements.</li></ul></li></ul></div></div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex1-headingTwo\"><button class=\"accordion-button fs-3 collapsed\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex1-collapseTwo\" aria-expanded=\"false\" aria-controls=\"ex1-collapseTwo\"><img src=\"images/magnifying_glass_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Solution:</button></h2><div id=\"ex1-collapseTwo\" class=\"accordion-collapse collapse\" aria-labelledby=\"ex1-headingTwo\" data-bs-parent=\"#accordionExercise1\"> <div class=\"accordion-body\"><h2>URL = https://pubmed.ncbi.nlm.nih.gov/<strong>39773557</strong>/</h2><p><strong>Note:</strong> The PMID is at the end of the URL</p> <img src=\"images/pubmed_1.png\" alt=\"Screenshot of PubMed record showing affiliation list expanded.\" class=\"img-fluid\" style=\"max-width: 100%; border-radius: 8px; padding: 1rem;\">\n",
    "  </div>\n",
    "  </div>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab5537-5ca1-4d05-a888-1820d23142f8",
   "metadata": {},
   "source": [
    "## Step 1. Construct an EFetch request\n",
    "To retrieve XML data for a PubMed article, use the following components:\n",
    "- **Base URL**: `https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi` \n",
    "- **Parameters**:\n",
    "    - **Database name**: `?db=pubmed`\n",
    "    - **Unique identifier**: `&id=39773557`\n",
    "    - **API key**: `&api_key=INSERT YOUR API KEY HERE`\n",
    "      \n",
    "Required parameters for an **EFetch** request depend on the specific Entrez [database]((https://www.ncbi.nlm.nih.gov/books/NBK25497/table/chapter2.T._entrez_unique_identifiers_ui/?report=objectonly)__) you are querying. For **PubMed**, the default EFetch response format is XML. \n",
    "\n",
    "To manage request volume, the **NCBI** enforces rate limits:\n",
    "- Without an API key: **3 requests per second**\n",
    "- With an API key: **up to 10 requests per second**\n",
    "\n",
    "While you can view a single XML record without an API key, completing the exercises in this tutorial requires one. You can obtain an API key by visiting the **Settings page of your [NCBI account](https://www.ncbi.nlm.nih.gov/account/)**.\n",
    "\n",
    "<div class=\"accordion\" id=\"accordionExercise2\">\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex2-headingOne\"><button class=\"accordion-button fs-3\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex2-collapseOne\" aria-expanded=\"true\" aria-controls=\"ex2-collapseOne\"><img src=\"images/guidepost_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Exercise 2: Construct a request</button></h2><div id=\"ex2-collapseOne\" class=\"accordion-collapse collapse show fs-4\" aria-labelledby=\"ex2-headingOne\" data-bs-parent=\"#accordionExercise2\"> <div class=\"accordion-body fs-4\">Use the <strong>EFetch</strong> utility to retrieve the <strong>XML record</strong> for the <strong>first PMID</strong> from the list you generated in Lesson 4. This XML will contain detailed metadata about the article, including author affiliations (if available). \n",
    "  </div></div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex2-headingTwo\"><button class=\"accordion-button fs-3 collapsed\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex2-collapseTwo\" aria-expanded=\"false\" aria-controls=\"ex2-collapseTwo\"><img src=\"images/magnifying_glass_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Solution:</button></h2><div id=\"ex2-collapseTwo\" class=\"accordion-collapse collapse\" aria-labelledby=\"ex2-headingTwo\" data-bs-parent=\"#accordionExercise2\"> <div class=\"accordion-body\"><h2>Example:</h2><p> <a href=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=39773557\">https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=39773557</a></p><img src=\"images/pubmed_2.png\" alt=\"Screenshot of PubMed XML record number 39773557\" class=\"img-fluid\" style=\"max-width: 100%; border-radius: 8px; padding: 1rem;\">\n",
    "\n",
    "  </div>\n",
    "  </div>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a536a-26fe-45f1-aa38-7cf7adf36a97",
   "metadata": {},
   "source": [
    "## Step 2. Identify Python libraries for project\n",
    "The following Python libraries are needed for this project:\n",
    "- `requests` ‚Äì to make HTTP requests\n",
    "- `pandas` ‚Äì to manage and store data\n",
    "- `BeautifulSoup`‚Äì to parse XML and extract affiliations\n",
    "\n",
    "<div class=\"accordion\" id=\"accordionExercise3\">\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex3-headingOne\"><button class=\"accordion-button fs-3\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex3-collapseOne\" aria-expanded=\"true\" aria-controls=\"ex3-collapseOne\"><img src=\"images/guidepost_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Exercise 3: Write and test code</button></h2><div id=\"ex3-collapseOne\" class=\"accordion-collapse collapse show fs-4\" aria-labelledby=\"ex3-headingOne\" data-bs-parent=\"#accordionExercise3\"> <div class=\"accordion-body fs-4\"><p>Using the list of PMIDs you generated in Lesson 4, write and test a Python script that:<ol><li>Iterates through your list of PMIDs</li><li>Sends an EFetch request for each\n",
    "</li><li>Parses the XML to extract author affiliations</li><li>Handles missing or incomplete data gracefully</li></ol></p>\n",
    "</div></div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"headingTwo\"><button class=\"accordion-button fs-3 collapsed\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#collapseTwo\" aria-expanded=\"false\" aria-controls=\"collapseTwo\"><img src=\"images/magnifying_glass_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Solution:</button></h2><div id=\"collapseTwo\" class=\"accordion-collapse collapse\" aria-labelledby=\"headingTwo\" data-bs-parent=\"#accordionExercise3\"> <div class=\"accordion-body\">\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "#1. Create a last_updated variable with today's date.\n",
    "today = date.today()\n",
    "last_updated=today\n",
    "\n",
    "#2. Create list of PMIDs\n",
    "pmids=['39773557', '39656677', '37398045', '39229161', '39713331', '39315813', '38338688', '36721057', '37322069']\n",
    "\n",
    "#3.Create a dataframe to store the search results. \n",
    "author_affiliations=pd.DataFrame(columns=[\"pmid\",\"name\",\"affiliation\",\"last_updated\"])\n",
    "\n",
    "#4. Use requests, BeautifulSoup, and the EFetch utility to retrieve author affiliations.\n",
    "# Store results in a DataFrame.\n",
    "count=0\n",
    "for each_record in pmids:\n",
    "    # try:\n",
    "    count += 1\n",
    "    print('starting record '+str(count)+': '+str(each_record))\n",
    "    search_url=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=\"+str(each_record)+\"&api_key=INSERT YOUR API KEY HERE\"\n",
    "    xml_data=requests.get(search_url).text\n",
    "    soup = bs(xml_data, 'xml')\n",
    "    records=soup.find('PubmedArticle')\n",
    "    pmid=records.PMID.text\n",
    "    authors=records.find_all(\"Author\")\n",
    "    for each_author in authors:\n",
    "        if each_author.LastName != None:\n",
    "            lastname=each_author.LastName.text\n",
    "        else:\n",
    "            lastname=''\n",
    "        if each_author.ForeName != None:\n",
    "            forename=each_author.ForeName.text\n",
    "        else:\n",
    "            forename=''\n",
    "        if lastname != '' and forename != '':\n",
    "            name=lastname+', '+forename\n",
    "        else:\n",
    "            name=''\n",
    "        \n",
    "\n",
    "        if each_author.Affiliation != None:\n",
    "            affiliation=each_author.Affiliation.text\n",
    "        else:\n",
    "            affiliation=''\n",
    "        print(f\"{name}, {affiliation}\")\n",
    "                \n",
    "        row={\n",
    "            \"pmid\": pmid,\n",
    "            \"name\": name,\n",
    "            \"affiliation\": affiliation,\n",
    "            \"last_updated\": last_updated\n",
    "\n",
    "            }\n",
    "        author_info=pd.DataFrame(row, index=[0])\n",
    "        author_affiliations = pd.concat([author_info,author_affiliations], axis=0)\n",
    "        time.sleep(0.15)\n",
    "        \n",
    "#5. Export results to csv        \n",
    "author_affiliations.to_csv('data/pubmed_author_affiliations.csv')\n",
    "```\n",
    "  </div>\n",
    "  </div>\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f88fc1-594d-42d9-b3e9-d8cc90485d0d",
   "metadata": {},
   "source": [
    "## Regular Expressions (regex)\n",
    "Analyzing author and affiliation data can be messy due to:\n",
    "- Inconsistent naming conventions\n",
    "- Variations in institutional affiliation formats\n",
    "- Ambiguities in author identify.\n",
    "\n",
    "<div class=\"card border-primary mb-3 p-1\" style=\"max-width: 100%;\">\n",
    "  <div class=\"card-header\" style=\"font-size: 1.8rem;\"><img src=\"images/idea_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Tip: ORCID</div>\n",
    "  <div class=\"card-body\"><img src=\"images/orcid_24x24.png\" alt=\"orcid logo\"><p><a href=\"https://orcid.org/register\">Create your ORCID iD</a>to help researchers distinguish your work from others and better track the impact of your work. </p><p>PubMed now embeds the ORCID in <span class=\"text-primary\">Author</span> tags. Several journals and funding agencies also now require ORCID iDs for submissions. See <a href=\"https://guides.osu.edu/c.php?g=608754&p=4233669\">Tracking and Enhacing the Impact of your Research</a> for more information.</p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "**Regular expressions (regex)** match patterns in text.  Often described as wildcards on steroids, regular expressions help:\n",
    "- **Validate** patterns (e.g., ZIP codes: (^\\d{5}$))\n",
    "- **Extract** variations (e.g., ‚Äúha?ematology‚Äù matches both ‚Äúhematology‚Äù and ‚Äúhaematology‚Äù)\n",
    "- **Replace** text (e.g., re.sub(r'\\bOH\\b', 'Ohio', text))\n",
    "\n",
    "Regular expressions are included in several programming langauges and software programs including Python, JavaScript, and Tableau. \n",
    "\n",
    "### Common Regex Patterns\n",
    "\n",
    "|     Pattern      | Matches  |  \n",
    "|:--------------|:--------------- |\n",
    "|`[A-Z]`    |Any uppercase letter   | \n",
    "|`[a-z]`    |Any lowercase letter   | \n",
    "|`[0-9]{5}`    |Exactly 5 digits  | \n",
    "|`^Ohio`    |Starts with \"Ohio\"  | \n",
    "|`State$`    |Ends with \"State\"  |\n",
    "|`ha?ematology`    |\"hematology\" or \"haematology\"  |\n",
    "|`Ohio State\\|OSU`    |\t\"Ohio State\" or \"OSU\"  |\n",
    "\n",
    "__[Metacharacters](https://www.w3schools.com/python/gloss_python_regex_metacharacters.asp)__ are special symbols in regular expressions that represent patterns rather than literal characters. To match them as literal characters, you must **escape them with a backslash ( \\ )**. \n",
    "\n",
    "### Common metacharacters and their functions\n",
    "|     Symbol     | Meaning  |  Example  |\n",
    "|:-------|:--------------- |:--------------- |\n",
    "|`[ ]`    |A set or range of characters   | `[a-f]` matches any lowercase letter from a to f  |\n",
    "| `\\`    |Starts a special sequence   | `\\w` matches any word character (letter, digit, or underscore) |\n",
    "| `.`   |\tAny character except newline   | `d.g` matches \"dog\", \"dig\", \"dug\", etc.  |\n",
    "| `^`   |Start of a string   | \t`^Ohio` matches any string that starts with \"Ohio\" |\n",
    "| `$`   |End of a string  | `State$` matches any string that ends with \"State\"  |\n",
    "| `.*`   |Zero or more of the preceding character   |`h*matology` matches \"hematology\", \"haematology\", etc. |\n",
    "| `+`   |One or more of the preceding character   | `spe+d` matches \"sped\", \"speed\", etc.  |\n",
    "| `?`   |Zero or one of the preceding character   | `travel?ling` matches \"traveling\", \"travelling\". etc. |\n",
    "| `{ }`   |Exactly a specified number of repetitions   | `[0-9]{5}` matches any 5-digit number  |\n",
    "| `( )`  |\tGrouping or capturing  | `The (Ohio) State University` extracts \"Ohio\"  |\n",
    "| `\\|`   |\tLogical OR   | `Ohio State\\|OSU` matches \"Ohio State\" or \"OSU\"  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1487ff0-67c5-4845-a1a0-984309cb7254",
   "metadata": {},
   "source": [
    "### LEARNING RESOURCES\n",
    "::: {.grid .g-4}\n",
    "::: {.g-col-12 .g-col-md-6 .g-col-lg-4}\n",
    "<div class=\"card bg-light mb-3\" style=\"max-width: 20rem;\">\n",
    "  <div class=\"card-header\">REGEX 101</div>\n",
    "  <div class=\"card-body\"><img src=\"images/regex101.png\" alt=\"Screenshot of regex101 homepage\" class=\"d-block mx-auto\"><h4 class=\"card-title\"><a href=\"https://regex101.com/\">regular expressions 101: build, test, and debug regex</h4>\n",
    "  </div>\n",
    "  <div> <a href=\"https://regex101.com/\">regular expressions 101: build, test, and debug regex</a> is an interactive tool that helps you build, test, and debug regular expressions across multiple programming languages. It lets you test your regex against sample text, provides real-time explanations as you type, and includes a searchable reference for regex syntax.</div>\n",
    "</div>\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.g-col-12 .g-col-md-6 .g-col-lg-4}\n",
    "<div class=\"card bg-light mb-3\" style=\"max-width: 20rem;\">\n",
    "  <div class=\"card-header\">EFFECTIVE DATA VISUALIZATION</div>\n",
    "  <div class=\"card-body\"><img src=\"images/cover_learning_regular_expressions.png\" alt=\"learning regular expressions book cover\" class=\"d-block mx-auto\" style=\"max-width: 100%; height: auto;\"><h4 class=\"card-title\"><a href=\"https://search.library.osu.edu/permalink/01OHIOLINK_OSU/rr4vai/alma991085516536408507\">Learning Regular Expressions</a></h4>\n",
    "  </div>\n",
    "  <div><a href=\"https://search.library.osu.edu/permalink/01OHIOLINK_OSU/rr4vai/alma991085516536408507\">Learning Regular Expressions</a> by <strong>Ben Forta</strong>** is available through the Libraries' <a href=\"https://search.library.osu.edu/permalink/01OHIOLINK_OSU/2g3e0k/alma991060545609708507\">O'Reilly Online Learning</a> collection of technical books and videos. Each chapter is structured as a lesson, guiding you through how to match individual characters or sets of characters, use metacharacters, and more‚Äîmaking it a practical resource for mastering regex step by step.\n",
    "  </div>\n",
    "\n",
    "</div>\n",
    "\n",
    ":::\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1af7b5",
   "metadata": {},
   "source": [
    "## re module\n",
    "To work with regular expressions in Python, start by importing the built-in `re` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceef738",
   "metadata": {},
   "source": [
    "üîó  See __[re](https://docs.python.org/3/library/re.html)__ module documentation.\n",
    "\n",
    "### Commonly used re methods\n",
    "\n",
    "### re.match( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(pattern, string, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b694c-5b6f-46a0-b800-32dab94d8396",
   "metadata": {},
   "source": [
    "- Checks for a match **only at the beginning** of the string.\n",
    "- Returns a match object if found, otherwise None.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d251f5-2248-4220-a388-a9edc3a5a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ohio State Biochemistry Program, The Ohio State University, Columbus, OH, 43210, USA. fu.978@osu.edu.\n",
      "The Ohio State Biochemistry Program, The Ohio State University, Columbus, OH, 43210, USA.\n",
      "Center for Cancer Metabolism, The Ohio State University Comprehensive Cancer Center, Columbus, OH, 43210, USA.\n",
      "Department of Biological Chemistry and Pharmacology, The Ohio State University, Columbus, OH, 43210, USA.\n",
      "Department of Biological Chemistry and Pharmacology, The Ohio State University, Columbus, OH, 43210, USA.\n",
      "The Ohio State Biochemistry Program, The Ohio State University, Columbus, OH, 43210, USA.\n",
      "Department of Biological Chemistry and Pharmacology, The Ohio State University, Columbus, OH, USA. fu.978@osu.edu.\n",
      "Department of Biological Chemistry and Pharmacology, The Ohio State University, Columbus, OH, USA.\n",
      "Department of Physics, Northeastern University, Boston, MA 02115, USA.\n",
      "Department of Chemistry and Biochemistry, Center for RNA Biology, Ohio State University, Columbus, OH 43210, USA.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "addresses=pd.read_csv('data/pubmed_author_affiliations.csv')\n",
    "addresses=addresses.dropna(subset='affiliation') #drops rows with null affiliation values\n",
    "\n",
    "for idx, row in addresses.iloc[0:10].iterrows():\n",
    "    affiliation=str(row.affiliation)\n",
    "    print(affiliation)\n",
    "    osu_match=re.match(r\"Ohio State University\",affiliation) \n",
    "    if osu_match:\n",
    "        print(f\" MATCH {osu_match.group()}: {affiliation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff01616",
   "metadata": {},
   "source": [
    "üîó  See [re.match()](https://docs.python.org/3/library/re.html#re.match) documentation.\n",
    "\n",
    "### re.search( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(pattern, string, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656d0b4-4fbc-42f0-8d20-666cecb8f940",
   "metadata": {},
   "source": [
    "- Scans through the string and returns the **first match** of the pattern.\n",
    "- Returns a match object or None.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a915cf18-06b4-49e8-a9c0-f1337f651d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "The Ohio State University\n",
      "No match: affiliation = Department of Physics, Northeastern University, Boston, MA 02115, USA.\n",
      "No match: affiliation = Department of Chemistry and Biochemistry, Center for RNA Biology, Ohio State University, Columbus, OH 43210, USA.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "addresses=pd.read_csv('data/pubmed_author_affiliations.csv')\n",
    "addresses=addresses.dropna(subset='affiliation')\n",
    "\n",
    "for idx, row in addresses.iloc[0:10].iterrows():\n",
    "    affiliation=str(row.affiliation)\n",
    "    # print(affiliation)\n",
    "    osu_search=re.search(r\"The Ohio State University\",affiliation) \n",
    "    if osu_search:\n",
    "        print(osu_search.group())\n",
    "    else:\n",
    "        print(f\"No match: affiliation = {affiliation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc77d1",
   "metadata": {},
   "source": [
    "üîó  See [re.search()](https://docs.python.org/3/library/re.html#re.search) documentation.\n",
    "\n",
    "### re.findall( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(pattern, string, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614e6a7-94f1-483b-9121-7bab0b591bb3",
   "metadata": {},
   "source": [
    "- Returns **all non-overlapping matches** of the pattern in the string as a list.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532ff7b1-5b53-4313-b2b1-0cf038bf4e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF ANIMALS\n",
      "abyssinian-ground-hornbill,addax,african-clawed-frog,african-pancake-tortoise,african-plated-lizard,aldabr-tortoise,allens-swamp-monkey,alligator-lizard,alligator-snapping-turtle,alpaca\n",
      "ANSWER\n",
      "There are 3 tortoises and turtles in this list of animals.\n"
     ]
    }
   ],
   "source": [
    "# HOW MANY TORTOISES AND TURTLES ARE IN THIS LIST OF ANIMALS?\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df=pd.read_csv('data/animals_tortoises.csv')\n",
    "animals=df.common_name.tolist()\n",
    "animals=','.join(animals)\n",
    "print('LIST OF ANIMALS')\n",
    "print(animals)\n",
    "\n",
    "tortoises_turtles=re.findall(r\"tortoise|turtle\", animals)\n",
    "print('ANSWER')\n",
    "print(f\"There are {len(tortoises_turtles)} tortoises and turtles in this list of animals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97193db4-6213-4db2-9c89-c61a247d6bad",
   "metadata": {},
   "source": [
    "üîó  See [re.findall()](https://docs.python.org/3/library/re.html#re.findall) documentation.\n",
    "\n",
    "### re.sub( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(pattern, repl, string, count=0, flags=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0b2c8",
   "metadata": {},
   "source": [
    "- Replaces all occurrences of the pattern in the string with the replacement text (`repl`).\n",
    "- You can limit the number of replacements using the count parameter.\n",
    "\n",
    "**Examples**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9deaa68-9090-4026-baf9-dc19cf682632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abyssinian-ground-hornbill,addax,african-clawed-frog,african-pancake-SLOW TORTOISE,,african-plated-lizard,aldabr-SLOW TORTOISE,,allens-swamp-monkey,alligator-lizard,alligator-snapping-SLOW TORTOISE,,alpaca'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIND TORTOISES AT THE NATIONAL ZOO AND REPLACE THE COMMON_NAME WITH \"SLOW TORTOISE\"\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df=pd.read_csv('data/animals_tortoises.csv')\n",
    "animals=df.common_name.tolist()\n",
    "animals=','.join(animals)\n",
    "pattern=\"tortoise|turtle\"\n",
    "tortoises_slow=re.sub(pattern,\"SLOW TORTOISE,\",animals)\n",
    "tortoises_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bc136-4245-4fce-8947-b7a214e08ea1",
   "metadata": {},
   "source": [
    "üîó  See [re.sub()](https://docs.python.org/3/library/re.html#re.sub) documentation.\n",
    "\n",
    "<div class=\"accordion\" id=\"accordionExercise4\">\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex4-headingOne\"><button class=\"accordion-button fs-3\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex4-collapseOne\" aria-expanded=\"true\" aria-controls=\"ex4-collapseOne\"><img src=\"images/guidepost_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Exercise 4: Use re to normalize affiliations</button></h2><div id=\"ex4-collapseOne\" class=\"accordion-collapse collapse show fs-4\" aria-labelledby=\"ex4-headingOne\" data-bs-parent=\"#accordionExercise4\"> <div class=\"accordion-body fs-4\">Use regular expressions to create a list of institution names from the affiliations list you generated in Exercise 3.</div></div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"accordion-item\"><h2 class=\"accordion-header\" id=\"ex4-headingTwo\"><button class=\"accordion-button fs-3 collapsed\" type=\"button\" data-bs-toggle=\"collapse\" data-bs-target=\"#ex4-collapseTwo\" aria-expanded=\"false\" aria-controls=\"ex4-collapseTwo\"><img src=\"images/magnifying_glass_standard_icon.png\" alt=\"\" aria-hidden=\"true\" style=\"height: 3rem; vertical-align: middle; margin-right: 0.5rem;\">Solution:</button></h2><div id=\"ex4-collapseTwo\" class=\"accordion-collapse collapse\" aria-labelledby=\"ex4-headingTwo\" data-bs-parent=\"#accordionExercise4\"> <div class=\"accordion-body\">\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "#1. Create a last_updated variable with today's date.\n",
    "today = date.today()\n",
    "last_updated=today\n",
    "\n",
    "#2. Create list of PMIDs\n",
    "pmids=['39773557', '39656677', '37398045', '39229161', '39713331', '39315813', '38338688', '36721057', '37322069']\n",
    "\n",
    "#3.Create a dataframe to store the search results. \n",
    "author_affiliations=pd.DataFrame(columns=[\"pmid\",\"name\",\"affiliation\",\"institution\",\"last_updated\"])\n",
    "\n",
    "#4. Use requests, BeautifulSoup, and the EFetch utility to retrieve author affiliations.\n",
    "# Store results in a DataFrame.\n",
    "count=0\n",
    "for each_record in pmids:\n",
    "    # try:\n",
    "    count += 1\n",
    "    print('starting record '+str(count)+': '+str(each_record))\n",
    "    search_url=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=\"+str(each_record)+\"&api_key=INSERT API KEY HERE\"\n",
    "    xml_data=requests.get(search_url).text\n",
    "    soup = bs(xml_data, 'xml')\n",
    "    records=soup.find('PubmedArticle')\n",
    "    pmid=records.PMID.text\n",
    "    authors=records.find_all(\"Author\")\n",
    "    for each_author in authors:\n",
    "        if each_author.LastName != None:\n",
    "            lastname=each_author.LastName.text\n",
    "        else:\n",
    "            lastname=''\n",
    "        if each_author.ForeName != None:\n",
    "            forename=each_author.ForeName.text\n",
    "        else:\n",
    "            forename=''\n",
    "        if lastname != '' and forename != '':\n",
    "            name=lastname+', '+forename\n",
    "        else:\n",
    "            name=''\n",
    "        \n",
    "\n",
    "        if each_author.Affiliation != None:\n",
    "            affiliation=each_author.Affiliation.text\n",
    "\n",
    "            ohio_state=re.search(r\"Ohio State\", affiliation)\n",
    "            harvard_medical_school=re.search(r\"Harvard Medical School\", affiliation)\n",
    "            institut_genetique=re.search(r\"Institut de G√©n√©tique et de Biologie Mol√©culaire et Cellulaire\", affiliation)\n",
    "            johns_hopkins=re.search(r\"Johns Hopkins University\", affiliation)\n",
    "            mcgill=re.search(r\"McGill University\", affiliation)\n",
    "            nci=re.search(r\"National Cancer Institute\", affiliation)\n",
    "            nidcd=re.search(r\"National Institute on Deafness and Other Communication Disorders\", affiliation)\n",
    "            northeastern=re.search(r\"Northeastern University\", affiliation)\n",
    "            u_bristol=re.search(r\"University of Bristol\", affiliation)\n",
    "            u_maryland=re.search(r\"University of Maryland\", affiliation)\n",
    "            u_virginia=re.search(r\"University of Virginia\", affiliation)\n",
    "            vicosa=re.search(r\"Universidade Federal de Vi√ßosa\", affiliation)\n",
    "            if ohio_state:\n",
    "                institution=\"The Ohio State University\"\n",
    "            elif harvard_medical_school:\n",
    "                institution=harvard_medical_school.group()\n",
    "            elif institut_genetique:\n",
    "                institution=institut_genetique.group()\n",
    "            elif johns_hopkins:\n",
    "                institution=johns_hopkins.group()\n",
    "            elif mcgill:\n",
    "                institution=mcgill.group()\n",
    "            elif nci:\n",
    "                institution=nci.group()\n",
    "            elif nidcd:\n",
    "                institution=nidcd.group()\n",
    "            elif northeastern:\n",
    "                institution=northeastern.group()\n",
    "            elif u_bristol:\n",
    "                institution=u_bristol.group()\n",
    "            elif u_maryland:\n",
    "                institution=u_maryland.group()\n",
    "            elif u_virginia:\n",
    "                institution=u_virginia.group()\n",
    "            elif vicosa:\n",
    "                institution=vicosa.group()\n",
    "\n",
    "        else:\n",
    "            affiliation=''\n",
    "        print(f\"{name}, {affiliation}\")\n",
    "\n",
    "        row={\n",
    "            \"pmid\": pmid,\n",
    "            \"name\": name,\n",
    "            \"affiliation\": affiliation,\n",
    "            \"institution\": institution,\n",
    "            \"last_updated\": last_updated\n",
    "\n",
    "            }\n",
    "        author_info=pd.DataFrame(row, index=[0])\n",
    "        author_affiliations = pd.concat([author_info,author_affiliations], axis=0)\n",
    "        time.sleep(0.15)\n",
    "        \n",
    "#5. Export results to csv        \n",
    "author_affiliations.to_csv('pubmed_author_affiliations.csv')\n",
    "```\n",
    "  </div>\n",
    "  </div>\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade7730",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
